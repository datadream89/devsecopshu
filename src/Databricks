import org.apache.spark.sql._
import org.apache.spark.sql.functions._
import org.apache.spark.sql.snowpark._

object CombineMultipleTablesExample {
  def main(args: Array[String]): Unit = {
    // Initialize the Snowpark session
    val session = Session.builder.config("snowflakeURL", "<snowflake_url>")
      .config("snowflakeUser", "<username>")
      .config("snowflakePassword", "<password>")
      .config("snowflakeDatabase", "<database>")
      .config("snowflakeWarehouse", "<warehouse>")
      .config("snowflakeRole", "<role>")
      .apply

    // List all tables in the database
    val allTableNames = session.catalog.listTables().map(_.name)

    // Filter tables with names containing "chain"
    val chainTableNames = allTableNames.filter(_.contains("chain"))

    // Load and union all tables with "chain" in their names
    var combinedTable: DataFrame = null
    chainTableNames.foreach { tableName =>
      val table = session.table(tableName)
      if (combinedTable == null) {
        combinedTable = table
      } else {
        combinedTable = combinedTable.union(table)
      }
    }

    // Create a new table called "logs" to store the combined data
    combinedTable.write
      .format("snowflake")
      .option("dbtable", "logs")
      .save()
  }
}
